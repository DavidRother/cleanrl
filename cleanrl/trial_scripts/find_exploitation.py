import math


def exploitation_probability_from_target_entropy(target_entropy, n, tol=1e-6, max_iter=1000):
    """
    Computes the exploitation probability p (i.e., probability of selecting the best action)
    given a SAC-style target entropy (a negative value) and the number of actions n.

    The distribution is assumed to be:
      - Best action: probability p
      - Other actions: probability (1-p) uniformly divided among the n-1 remaining actions

    The entropy of such a distribution is:
      H(p) = -[ p * log(p) + (1-p) * log((1-p)/(n-1)) ]

    Parameters:
      target_entropy (float): SAC target entropy (negative value). Desired entropy is H_desired = -target_entropy.
      n (int): Number of actions.
      tol (float): Tolerance for the bisection method.
      max_iter (int): Maximum number of iterations for the bisection search.

    Returns:
      float: The exploitation probability p.
    """
    # Convert SAC target entropy (negative) to desired positive entropy value.
    H_desired = -target_entropy

    # The maximum possible entropy for a discrete distribution over n actions is achieved with a uniform distribution.
    H_max = math.log(n)
    if H_desired > H_max:
        raise ValueError(f"Desired entropy {H_desired:.4f} is too high for {n} actions; maximum is {H_max:.4f}.")
    if H_desired < 0:
        raise ValueError("Desired entropy must be non-negative.")

    def f(p):
        # p must be strictly between 0 and 1.
        if p <= 0 or p >= 1:
            return None
        return - (p * math.log(p) + (1 - p) * math.log((1 - p) / (n - 1))) - H_desired

    # Lower bound: p = 1/n (uniform distribution over actions gives maximum entropy)
    low = 1.0 / n
    # Upper bound: use a value just below 1 to avoid log(0)
    high = 1.0 - tol

    f_low = f(low)
    f_high = f(high)

    if f_low is None or f_high is None:
        raise ValueError("Invalid function bounds encountered.")

    # For typical target entropy values:
    # - At p = 1/n, H(p)= log(n). So if target_entropy is -log(n) then f(low)=0.
    # - At p = 1.0, H(p)=0, so f(high)= -H_desired (which is negative if H_desired > 0).
    if f_low < 0:
        # If f(low) is negative, then the desired entropy is lower than that at uniform distribution.
        raise ValueError("Bisection method assumptions not met at lower bound. Check target_entropy value.")
    if f_high > 0:
        # f(high) should be negative; if not, then raise an error.
        raise ValueError("Bisection method assumptions not met at upper bound. Check target_entropy value.")

    # If the lower bound is already a solution, return it.
    if abs(f_low) < tol:
        return low

    # Bisection search to find p such that f(p) = 0.
    iter_count = 0
    while high - low > tol and iter_count < max_iter:
        mid = (low + high) / 2.0
        f_mid = f(mid)
        if f_mid is None:
            break  # Should not happen with our bounds.
        if abs(f_mid) < tol:
            return mid
        if f_mid > 0:
            # The computed entropy is too high (f_mid positive) => increase p to reduce entropy.
            low = mid
        else:
            # The computed entropy is too low => decrease p.
            high = mid
        iter_count += 1

    return (low + high) / 2.0


if __name__ == "__main__":
    # Example: 5 actions
    n = 18

    # Default SAC heuristic for discrete environments: target_entropy = -log(n)
    default_target_entropy = -math.log(n)
    p_default = exploitation_probability_from_target_entropy(default_target_entropy, n)

    print("For n = {} actions".format(n))
    print("Default target entropy (-log(n)) = {:.4f}".format(default_target_entropy))
    print("Exploitation probability p = {:.4f}".format(p_default))

    # Custom example: target entropy corresponding to a more exploitative distribution,
    # e.g., one where p (best action probability) might be near 0.9.
    # From earlier calculations, for n=5, this corresponds to an entropy of about 0.4637 nats,
    # so the SAC target entropy is set to -0.4637.
    target_entropy_custom = -0.4637
    p_custom = exploitation_probability_from_target_entropy(target_entropy_custom, n)

    print("\nCustom target entropy = {:.4f}".format(target_entropy_custom))
    print("Exploitation probability p = {:.4f}".format(p_custom))

    target_entropy = -0.89
    print(f"For target entropy: {target_entropy}")
    for n in range(4, 20):
        print(f"Num actions: {n}")
        p_custom = exploitation_probability_from_target_entropy(target_entropy, n)
        print(f"The probability of exploitation for the best action comes down to: {p_custom}")
        p_default = exploitation_probability_from_target_entropy(-math.log(n), n)
        print(f"The probability of exploitation for the best action with default choice comes down to: {p_default}")

